{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rcdQr-6s_cKM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка датасета"
      ],
      "metadata": {
        "id": "0tuI3_Zssxpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим преобразования для данных\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Загрузим обучающий и тестовый наборы данных\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Разделим обучающий набор на обучающую и валидационную выборки\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Определим загрузчики данных\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "jyD1lIQg_l0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d18b59-056f-4db4-db88-bb2c81d93ab6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 52231711.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1806350.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 12623326.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6654044.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание класса простой полносвязной нейронной сети"
      ],
      "metadata": {
        "id": "8zlzI2ShtFLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Инициализация модели, критерия и оптимизатора\n",
        "model1 = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "FTDA4wKu_5Cq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, train_loader, val_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}\")\n"
      ],
      "metadata": {
        "id": "mn4SwX6zAEOK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение полносвязанной нейронной сети\n",
        "train(model1, optimizer1, criterion, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw5Ipe6rAHyS",
        "outputId": "ec06a489-ec46-4b07-db5c-f4d46934c075"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 0.22698038081079722, Validation Loss: 0.1256291949081215\n",
            "Epoch 2/10, Training Loss: 0.0939226277495424, Validation Loss: 0.1145543840396753\n",
            "Epoch 3/10, Training Loss: 0.06662066135027757, Validation Loss: 0.11324446808368444\n",
            "Epoch 4/10, Training Loss: 0.04855739006520404, Validation Loss: 0.09792500184576443\n",
            "Epoch 5/10, Training Loss: 0.03802499145960125, Validation Loss: 0.08467931223369421\n",
            "Epoch 6/10, Training Loss: 0.03131451450916938, Validation Loss: 0.12517419279964165\n",
            "Epoch 7/10, Training Loss: 0.02882078992992562, Validation Loss: 0.09435964111013319\n",
            "Epoch 8/10, Training Loss: 0.024709180767609116, Validation Loss: 0.10892689883807412\n",
            "Epoch 9/10, Training Loss: 0.022180620793020352, Validation Loss: 0.10152326824901776\n",
            "Epoch 10/10, Training Loss: 0.0225430518453965, Validation Loss: 0.10716780891070425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "# Тестирование полносвязанной нейронной сети\n",
        "test(model1, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56f8MV16D8fh",
        "outputId": "44e46229-8008-46fb-fc3a-02bef523394c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой работе мы обучили нейронную сеть распознавать рукописные буквы, используя датасет MNIST. Датасет состоит из изображений цифр от 0 до 9 размером 28x28 пикселей. Мы использовали библиотеку torchvision для загрузки и предварительной обработки данных.\n",
        "\n",
        "**Преобразования и загрузка данных**\n",
        "\n",
        "Мы применили следующие преобразования к изображениям:\n",
        "\n",
        "1.   Преобразование изображения в тензор с помощью ToTensor\n",
        "2.   Нормализация данных с помощью Normalize\n",
        "\n",
        "Затем мы загрузили обучающий и тестовый наборы данных с использованием функции torchvision.datasets.MNIST. Обучающий набор данных был разделен на две части: 80% данных использовались для обучения, а оставшиеся 20% — для валидации. Это было сделано с помощью функции random_split.\n",
        "Для эффективного обучения и тестирования мы использовали DataLoader с размером батча 64.\n",
        "\n",
        "**Архитектура модели**\n",
        "\n",
        "Мы создали простую полносвязанную нейронную сеть SimpleNN, состоящую из трех полносвязанных слоев:\n",
        "\n",
        "Первый слой: вход 28*28 нейронов, выход 512 нейронов\n",
        "Второй слой: вход 512 нейронов, выход 256 нейронов\n",
        "Третий слой: вход 256 нейронов, выход 10 нейронов (по числу классов)\n",
        "Для активации использовалась функция ReLU.\n",
        "\n",
        "Мы использовали функцию потерь CrossEntropyLoss и оптимизатор Adam с начальной скоростью обучения 0.001.\n",
        "\n",
        "**Процесс обучения**\n",
        "Обучение модели проводилось в течение 10 эпох. В каждой эпохе:\n",
        "\n",
        "1. Модель обучалась на обучающем наборе данных, и накапливалась средняя величина функции потерь\n",
        "2. Модель оценивалась на валидационном наборе данных, и также вычислялась средняя величина функции потерь\n",
        "\n",
        "В процессе обучения наблюдалось следующее:\n",
        "\n",
        "* Средняя величина функции потерь на обучающем наборе данных постепенно уменьшалась.\n",
        "* Величина функции потерь на валидационном наборе данных не показывала значительного роста, что указывает на отсутствие переобучения.\n",
        "\n",
        "**Тестирование**\n",
        "\n",
        "Для того, чтобы провести тестирование мы:\n",
        "\n",
        "1. Переключаем модель в режим оценки методом model.eval()\n",
        "2. Отключаем градиентное вычисление методом torch.no_grad(), так как нам не нужны градиенты для оценки модели\n",
        "3. В цикле мы перебираем все батчи изображений и меток из test_loader\n",
        "4. Получаем предсказания модели\n",
        "5. Сравниваем предсказанные модели с истинными значениями. Метрика Accuracy считает отношение верно угаданных значений к общему количеству.\n",
        "\n",
        "Точность модели составила **97.69%**\n",
        "\n",
        "Это довольно хороший показатель, поэтому мы можем сказать, что наша архитектура простой полносвязанной нейронной сети оказалась крайне эффективна для задачи распознавания рукописных цифр."
      ],
      "metadata": {
        "id": "bYGuFYe_xRJk"
      }
    }
  ]
}